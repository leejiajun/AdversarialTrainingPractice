# AdversarialTrainingPractice

## 工具：
- AutoAttack [https://github.com/fra31/auto-attack]
- FoolBox [https://github.com/bethgelab/foolbox]: 找the worst-case很发方便
- cleverhans [https://github.com/cleverhans-lab/cleverhans]: 收录了benchmark的attck, 社区活跃
- advertorch [https://github.com/BorealisAI/advertorch]: 很久没维护了

## 论文：
- On Evaluating Adversarial Robustness [https://github.com/evaluating-adversarial-robustness/adv-eval-paper]: 开源，可以去贡献Cancel Changes
- Obfuscated Gradients Give a False Sense of Security: Circumventing Defenses to Adversarial Examples: 探讨gradient masking, 自行补充和Goodfellow相关的八卦
- Adversarial Machine Learning at Scale [https://arxiv.org/abs/1611.01236]: 讲到了leaking label现象，重要
